### 并发基础

可以使用 ```runtime.GOMAXPROCS(1)``` 将设置golang 应用只使用一个操作系统线程。使用```g := runtime.GOMAXPROCS(0)```可以设置golang应用使用尽量多的操作系统线程，这对于`container`环境下有很大意义，因为可以对比返回的线程数量和容器环境下分配给应用的cpu线程数量是否相等，如果不相等需要做一定调整，以达到系统最佳运行效果。


### 6.3 抢占scheduler

`Golang scheduler` 是基于抢占式的，所以在没有相关同步机制的情况下，不能对`go-routine`调度策略做任何的假设。比如：

```go

func main() {
    var wg sync.WaitGroup
    wg.Add(2)
    go func() {
        printHashes("A")
        wg.Done()
  }()

  go func() {
        printHashes("B")
        wg.Done()
  }()
  fmt.Println("Waiting To Finish")
  wg.Wait()
  fmt.Println("\nTerminating Program")
}

func printHashes(prefix string) {
    for i := 1; i <= 50000; i++ {
          num := strconv.Itoa(i)
          sum := sha1.Sum([]byte(num))
          fmt.Printf("%s: %05d: %x\n", prefix, i, sum)
  }
  fmt.Println("Completed", prefix)
}

```

统计context switching 次数：

```bash
$ ./example2 | cut -c1 | grep '[AB]' | uniq
B
A
B
A
B
A
B
A
B
A  9 Context Switches
$ ./example2 | cut -c1 | grep '[AB]' | uniq
B
A
B
A  3 Context Switches

```


可以发现每次运行代码，结果都不一样，因此不能对逻辑做太多假设。


### 6.4数据竟态

数据竟态主要发生在当多个cpu线程对同一片数据同时进行读写时，会导致数据竟态。对于数据竟态如果没有合理的同步机制，会导致代码逻辑异常。即使引入了同步机制后，也可能存在多个cpu同时访问同一片`cache line`，导致多个cpu对于`cache-line`的频繁同步，导致性能下降。


### 6.5 数据竟态实例

数据竟态问题是非常难以察觉和修复的。

```go
var counter int
func main() {
    const grs = 2
    var wg sync.WaitGroup
    wg.Add(grs)
    for g := 0; g < grs; g++ {
        go func() {
            for i := 0; i < 2; i++ {
                value := counter   //对全局变量进行了一次读，如果其他cpu对于counter已经有变更了，那么需要同步cache line，性能降低
                value++           //此时如果调度到其他的go-routine，会导致其他go-routine读到原来的counter，出现“幻读/幻写”
                counter = value  //进行了一次设置，此时其他的cpu的`cache-line` 被设置为dirty 
            }
            wg.Done()
        }()
    }
    wg.Wait()
    fmt.Println("Counter:", counter)
}
```

多次运行程序，结果都一样，couter结果都是4，但是并不代表代码逻辑是没有问题的。
```go

var counter int
func main() {
    const grs = 2
    var wg sync.WaitGroup
    wg.Add(grs)
    for g := 0; g < grs; g++ {
        go func() {
            for i := 0; i < 2; i++ {
                value := counter   //对全局变量进行了一次读，如果其他cpu对于counter已经有变更了，那么需要同步cache line，性能降低
                value++           //此时如果调度到其他的go-routine，会导致其他go-routine读到原来的counter，出现“幻读/幻写”
                log.Println("logging") // 此处增加了日志打印，有IO操作，此时会发生调度
                counter = value  //进行了一次设置，此时其他的cpu的`cache-line` 被设置为dirty 
            }
            wg.Done()
        }()
    }
    wg.Wait()
    fmt.Println("Counter:", counter)
}
```

此时在运行代码，发现结果是2，并不是4，触发了代码中的"幻读"。


### 数据竟态探测

如上所示的例子，数据竟态的问题探测是十分重要的，那么如何探测呢？

```bash
  go build -race
  ./example 
```

以上编译流程会导致程序的运行效率降低20%，但是却具有数据竟态检测能力。

``` bash
2021/02/01 17:30:52 logging
2021/02/01 17:30:52 logging
2021/02/01 17:30:52 logging
==================
WARNING: DATA RACE
Write at 0x000001278d88 by goroutine 8:
  main.main.func1()
      /data_race/example1/example1.go:41 +0xa6
Previous read at 0x000001278d88 by goroutine 7:
  main.main.func1()
      /data_race/example1/example1.go:38 +0x4a
Goroutine 8 (running) created at:
  main.main()
      /data_race/example1/example1.go:36 +0xaf
Goroutine 7 (finished) created at:
  main.main()
      /data_race/example1/example1.go:36 +0xaf
==================
2021/02/01 17:30:52 logging
Final Counter: 2
Found 1 data race(s)
```

可以发现已经发现了数据竟态问题。

![data_race_dect](/ch6/images/data_race_dect.png)

如上所示，38行和第41行有数据竟态问题。

### 6.7 atomics

如上所示的例子如何修复呢 ？可以使用atomic(原子操作)，来解决。`atomics`的实现方式有很多种，很多实现都是基于硬件，比如CAS或者基于cache-line实现等。`atomics` 的优势在于`go-routine`处于自旋状态，不会发生`context switching`，这对于异常短暂的操作，可以有效提高计算资源利用效率。

```go

var counter int32
func main() {
    const grs = 2
    var wg sync.WaitGroup
    wg.Add(grs)
    for g := 0; g < grs; g++ {
        go func() {
            for i := 0; i < 2; i++ {
                atomic.AddInt32(&counter, 1) // 增加atomic，防止数据竟态问题
            wg.Done()
        }()
  }
  wg.Wait()
      fmt.Println("Counter:", counter)
  }
}
```


### 6.8 Mutex

如上所示的例子，还可以通过`mutex`来解决。
```go
func main() {
  const grs = 2
  var wg sync.WaitGroup
  wg.Add(grs)
  var mu sync.Mutex
  for g := 0; g < grs; g++ {
      go func() {
          for i := 0; i < 2; i++ {
              mu.Lock() //加锁，保护数据
              {
                  value := counter
                  value++
                  counter = value
              }
              mu.Unlock()//释放锁
          wg.Done()
      }()
  }
  wg.Wait()
      fmt.Println("Counter:", counter)
  }
```

如上所示，可以说过`mutex`加锁保护数据，`mutex`与`automic`的区别在于`mutex`可以保护一段代码，但是`automic`能保证正常访问/读写数据。

golang对于mutex的实现做了优化，mutex有两种模式：

- 正常模式，对于mutex加锁或进行自旋，当某个go-routine等待时间超过1M ns后，转换为饥饿模式
- 饥饿模式，对于mutex加锁直接加入到队列尾端，即使是当前锁是空闲的，也需要排队



### 读写锁

对于读多写少的情况，读写锁更适合。 读写锁原理为：

- 加读锁，对于没有写锁的情况下，直接对于已有读计数增加1，
  - 如果已经有写锁，读锁等待计数+1， 排队等待
  - 如果有读锁等待，则读锁等待计数+1
  - 如果没有写锁，直接正在读锁计数+1 
  - 释放读锁时，如果没有正在执行的读锁，并且有写锁等待，则唤醒写锁
- 加写锁
  - 如果已经有读锁，将读锁计数-maxlockcount，标示有写锁等待
  - 如果有写锁，则等待
  - 如果没有写锁则加锁成功
  - 释放锁时，如果有读锁等待，则唤醒读锁





